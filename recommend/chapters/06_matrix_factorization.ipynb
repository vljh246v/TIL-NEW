{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 행렬 분해 기법(Matrix Factorization)\n",
    "\n",
    "이 챕터에서는 협업 필터링의 모델 기반 접근법인 행렬 분해(Matrix Factorization) 기법을 구현합니다. 사용자-아이템 평점 행렬을 저차원의 잠재 요인(latent factor) 행렬로 분해하여 누락된 평점을 예측하는 방식입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "import os\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nfrom typing import Dict, List\n\n# 상위 디렉토리 경로를 시스템 경로에 추가하여 utils 모듈을 import할 수 있게 함\nsys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n\n# utils 모듈에서 필요한 클래스와 함수를 import\nfrom utils.models import Dataset, RecommendResult, Metrics\nfrom utils.data_loader import DataLoader",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 행렬 분해 추천 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class MFRecommender(BaseRecommender):\n",
    "    \"\"\"행렬 분해(Matrix Factorization) 기반 추천 시스템\n",
    "\n",
    "    사용자-아이템 평점 행렬을 저차원의 잠재 요인(latent factor) 행렬로 분해하여\n",
    "    누락된 평점을 예측하는 방식입니다. 구현된 알고리즘은 SGD(Stochastic Gradient Descent)를\n",
    "    사용하여 최적화하는 기본적인 행렬 분해 모델입니다.\n",
    "\n",
    "    모델 수식:\n",
    "    예측 평점 r̂_ui = μ + bu + bi + p_u · q_i^T\n",
    "    여기서:\n",
    "    - μ: 전체 평균 평점\n",
    "    - bu: 사용자 u의 편향(bias)\n",
    "    - bi: 아이템 i의 편향(bias)\n",
    "    - p_u: 사용자 u의 잠재 요인 벡터\n",
    "    - q_i: 아이템 i의 잠재 요인 벡터\n",
    "\n",
    "    알고리즘 로직:\n",
    "    1. 전처리:\n",
    "       - 사용자 ID와 영화 ID를 내부 인덱스로 매핑\n",
    "       - 전체 평균(μ) 계산\n",
    "       - 사용자 요인 행렬(P), 아이템 요인 행렬(Q) 초기화\n",
    "       - 사용자 편향(bu), 아이템 편향(bi) 초기화\n",
    "\n",
    "    2. SGD 학습:\n",
    "       - 모든 학습 데이터에 대해 n_epochs 횟수만큼 반복\n",
    "       - 각 평점에 대해:\n",
    "         a. 현재 모델로 평점 예측\n",
    "         b. 오차(e) 계산\n",
    "         c. 경사하강법으로 파라미터 업데이트:\n",
    "            - 사용자 편향(bu) 업데이트\n",
    "            - 아이템 편향(bi) 업데이트\n",
    "            - 사용자 요인 벡터(P[u]) 업데이트\n",
    "            - 아이템 요인 벡터(Q[i]) 업데이트\n",
    "\n",
    "    3. 평점 예측 (RMSE 계산용):\n",
    "       - 테스트 데이터의 각 항목에 대해 학습된 모델로 평점 예측\n",
    "       - 예측값을 0.5~5.0 범위로 제한\n",
    "\n",
    "    4. 아이템 추천:\n",
    "       - 각 사용자에 대해 모든 아이템의 예측 평점 계산\n",
    "       - 이미 평가한 아이템을 제외하고 예측 평점이 높은 상위 k개 추천\n",
    "\n",
    "    매개변수:\n",
    "    - k: 추천 목록 크기 (기본값: 10)\n",
    "    - n_factors: 잠재 요인의 차원 수 (기본값: 20)\n",
    "    - learning_rate: 학습률 (기본값: 0.01)\n",
    "    - n_epochs: 반복 학습 횟수 (기본값: 50)\n",
    "    - reg: 정규화 계수 (기본값: 0.08)\n",
    "\n",
    "    특징:\n",
    "    - 메모리 기반 협업 필터링(UserKNN, ItemKNN)보다 일반적으로 더 높은 정확도\n",
    "    - 대용량 데이터에서도 효율적으로 학습 가능\n",
    "    - 사용자와 아이템의 잠재적 특성을 학습하여 데이터 희소성 문제를 완화\n",
    "    \"\"\"\n",
    "    def recommend(self, dataset: Dataset, k=10, **kwargs) -> RecommendResult:\n",
    "        np.random.seed(0)  # 재현성을 위한 시드 고정\n",
    "        # 하이퍼파라미터 설정\n",
    "        n_factors = kwargs.get('n_factors', 20)  # 잠재 요인 차원\n",
    "        lr = kwargs.get('learning_rate', 0.01)  # 학습률\n",
    "        n_epochs = kwargs.get('n_epochs', 50)   # 반복 학습 횟수\n",
    "        reg = kwargs.get('reg', 0.08)           # 정규화 계수\n",
    "\n",
    "        train, test = dataset.train, dataset.test\n",
    "        mu = float(train['rating'].mean())  # 전체 평균 평점\n",
    "\n",
    "        # ID를 내부 인덱스로 매핑\n",
    "        users = sorted(train.userId.unique())\n",
    "        items = sorted(train.movieId.unique())\n",
    "        uid2i = {u:i for i,u in enumerate(users)}  # 사용자 ID → 인덱스\n",
    "        iid2j = {m:j for j,m in enumerate(items)}  # 영화 ID → 인덱스\n",
    "        nU, nI = len(users), len(items)  # 사용자 수, 아이템 수\n",
    "\n",
    "        # 모델 파라미터 초기화\n",
    "        P = 0.1*np.random.randn(nU, n_factors)  # 사용자 요인 행렬\n",
    "        Q = 0.1*np.random.randn(nI, n_factors)  # 아이템 요인 행렬\n",
    "        bu = np.zeros(nU)  # 사용자 편향\n",
    "        bi = np.zeros(nI)  # 아이템 편향\n",
    "\n",
    "        # 학습 데이터 인덱스 매핑\n",
    "        df = train.copy()\n",
    "        df['ui'] = df['userId'].map(uid2i)  # 사용자 ID → 인덱스\n",
    "        df['ij'] = df['movieId'].map(iid2j)  # 영화 ID → 인덱스\n",
    "\n",
    "        # SGD로 모델 학습\n",
    "        for _ in range(n_epochs):\n",
    "            for r in df.itertuples(index=False):\n",
    "                u, j, y = int(r.ui), int(r.ij), float(r.rating)\n",
    "                # 예측값 계산: μ + bu + bi + p_u·q_i^T\n",
    "                pred = mu + bu[u] + bi[j] + P[u].dot(Q[j])\n",
    "                # 오차 계산\n",
    "                e = y - pred\n",
    "                # 파라미터 업데이트\n",
    "                bu[u] += lr*(e - reg*bu[u])  # 사용자 편향 업데이트\n",
    "                bi[j] += lr*(e - reg*bi[j])   # 아이템 편향 업데이트\n",
    "                Pu = P[u].copy(); Qj = Q[j].copy()  # 원본 보존\n",
    "                P[u] += lr*(e*Qj - reg*Pu)   # 사용자 요인 업데이트\n",
    "                Q[j] += lr*(e*Pu - reg*Qj)   # 아이템 요인 업데이트\n",
    "\n",
    "        # RMSE 계산을 위한 평점 예측\n",
    "        pred = pd.Series(index=test.index, dtype=float)\n",
    "        for idx, row in test.iterrows():\n",
    "            u, m = row['userId'], row['movieId']  # 사용자 ID와 영화 ID\n",
    "            # 학습 데이터에 없는 사용자나 아이템은 전체 평균 사용\n",
    "            if (u not in uid2i) or (m not in iid2j):\n",
    "                pred.at[idx] = mu\n",
    "            else:\n",
    "                # 인덱스 매핑\n",
    "                ui = uid2i[u]; ij = iid2j[m]\n",
    "                # 예측값 계산: μ + bu + bi + p_u·q_i^T\n",
    "                pred.at[idx] = mu + bu[ui] + bi[ij] + P[ui].dot(Q[ij])\n",
    "        # 예측값 범위 조정 (0.5~5.0)\n",
    "        pred = pred.clip(lower=0.5, upper=5.0)\n",
    "\n",
    "        # 추천 목록 생성\n",
    "        seen = train.groupby('userId')['movieId'].apply(set).to_dict()\n",
    "        user2items = defaultdict(list)\n",
    "        for u in test['userId'].unique():\n",
    "            # 학습 데이터에 없는 사용자는 모든 아이템에 평균 점수 부여\n",
    "            if u not in uid2i:\n",
    "                scores = {m: mu for m in items}\n",
    "            else:\n",
    "                # 모든 아이템에 대한 예측 점수를 한 번에 계산\n",
    "                ui = uid2i[u]\n",
    "                s = mu + bu[ui] + bi + Q @ P[ui]  # 행렬 곱을 통한 벡터화 연산\n",
    "                scores = {items[j]: float(s[j]) for j in range(nI)}\n",
    "            # 점수가 높은 순서로 상위 k개 아이템 추천\n",
    "            user2items[u] = _recommend_sorted(scores, seen.get(u,set()), k)\n",
    "\n",
    "        return RecommendResult(pred, user2items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 행렬 분해 알고리즘 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 데이터셋 로드\n",
    "loader = DataLoader(num_users=100)\n",
    "dataset = loader.load()\n",
    "\n",
    "# 메트릭스 계산기\n",
    "mc = MetricCalculator()\n",
    "K = 10  # 추천 목록 크기\n",
    "\n",
    "# MF 평가 (다양한 잠재 요인 차원으로 실험)\n",
    "print(\"\\n=== Matrix Factorization 평가 ===\")\n",
    "mf_results = []\n",
    "for n_factors in [10, 20, 50]:\n",
    "    mf_recommender = MFRecommender()\n",
    "    mf_result = mf_recommender.recommend(\n",
    "        dataset,\n",
    "        k=K, \n",
    "        n_factors=n_factors, \n",
    "        learning_rate=0.02, \n",
    "        n_epochs=30, \n",
    "        reg=0.08\n",
    "    )\n",
    "    metrics = mc.calc(\n",
    "        dataset.test['rating'].tolist(),\n",
    "        mf_result.rating.tolist(),\n",
    "        dataset.test_user2items,\n",
    "        mf_result.user2items,\n",
    "        k=K,\n",
    "        params={\"model\": \"MF\", \"n_factors\": n_factors}\n",
    "    )\n",
    "    mf_results.append(metrics)\n",
    "    print(f\"MF (n_factors={n_factors}):\", metrics)\n",
    "\n",
    "# 최고 성능의 MF 선택\n",
    "best_mf = max(mf_results, key=lambda x: (x.precision_at_k, -x.rmse))\n",
    "print(\"Best MF:\", best_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 행렬 분해 기법의 장단점\n",
    "\n",
    "### 장점\n",
    "1. **높은 예측 정확도**: 메모리 기반 방법보다 일반적으로 더 정확한 예측을 제공\n",
    "2. **확장성**: 대용량 데이터에서도 효율적으로 학습 및 예측 가능\n",
    "3. **잠재 요인 학습**: 데이터에서 숨겨진 패턴과 잠재적 특성을 자동으로 학습\n",
    "4. **희소성 문제 완화**: 적은 평가 데이터로도 합리적인 예측 가능\n",
    "5. **데이터 압축**: 원래 행렬보다 훨씬 작은 공간에 정보 저장 가능\n",
    "\n",
    "### 단점\n",
    "1. **블랙박스 특성**: 잠재 요인의 의미를 직관적으로 해석하기 어려움\n",
    "2. **하이퍼파라미터 튜닝**: 최적의 성능을 위해 많은 파라미터 튜닝이 필요\n",
    "3. **추천 설명의 어려움**: 추천 결과의 이유를 사용자에게 설명하기 어려움\n",
    "4. **새로운 사용자/아이템 처리**: 콜드 스타트 문제가 여전히 존재\n",
    "5. **학습 시간**: 초기 학습에 상대적으로 오랜 시간이 필요\n",
    "\n",
    "### 성능 최적화 팁\n",
    "- **최적의 잠재 요인 차원 찾기**: 그리드 서치를 통해 n_factors 최적화\n",
    "- **학습률과 정규화 계수 조절**: 과적합과 수렴 속도 사이의 균형 조절\n",
    "- **초기화 전략 개선**: 랜덤 초기화 대신 SVD 기반 초기화 사용\n",
    "- **조기 종료(Early Stopping)**: 검증 데이터에서 성능이 더 이상 향상되지 않으면 학습 종료\n",
    "- **암묵적 피드백(Implicit Feedback) 통합**: 평점 외에도 클릭, 시청 시간 등의 추가 정보 활용\n",
    "\n",
    "### 확장 모델\n",
    "- **SVD++**: 암묵적 피드백을 통합하여 MF 모델 확장\n",
    "- **시간적 요소 고려**: 시간에 따른 사용자 취향 변화 모델링\n",
    "- **Neural Collaborative Filtering**: 딥러닝을 적용하여 비선형 관계 모델링\n",
    "- **Factorization Machines**: 추가 특성 정보를 포함한 모델링"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}