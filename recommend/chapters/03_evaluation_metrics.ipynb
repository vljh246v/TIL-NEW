{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 평가 메트릭스 구현\n",
    "\n",
    "이 챕터에서는 추천 시스템의 성능을 평가하기 위한 다양한 메트릭스를 구현합니다. RMSE(Root Mean Squared Error)를 통한 평점 예측 정확도와 Precision@K, Recall@K를 통한 추천 품질을 측정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "import os\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, List\nfrom sklearn.metrics import mean_squared_error\n\n# 상위 디렉토리 경로를 시스템 경로에 추가하여 utils 모듈을 import할 수 있게 함\nsys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n\n# utils 모듈에서 필요한 클래스 import\nfrom utils.models import Metrics",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 평가 메트릭스 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class MetricCalculator:\n",
    "    def calc(self, true_rating: List[float], pred_rating: List[float],\n",
    "             true_user2items: Dict[int, List[int]],\n",
    "             pred_user2items: Dict[int, List[int]], k: int, params: Dict=None) -> Metrics:\n",
    "        rmse = self._calc_rmse(true_rating, pred_rating)\n",
    "        p = self._calc_precision_at_k(true_user2items, pred_user2items, k)\n",
    "        r = self._calc_recall_at_k(true_user2items, pred_user2items, k)\n",
    "        return Metrics(rmse, p, r, params or {})\n",
    "\n",
    "    def _calc_rmse(self, y, yhat) -> float:\n",
    "        \"\"\"\n",
    "        실제 평점과 예측 평점 사이의 Root Mean Squared Error를 계산합니다.\n",
    "        \n",
    "        Args:\n",
    "            y: 실제 평점 리스트\n",
    "            yhat: 예측 평점 리스트\n",
    "            \n",
    "        Returns:\n",
    "            RMSE 값 (낮을수록 좋음)\n",
    "        \"\"\"\n",
    "        if not y or not yhat: return np.nan\n",
    "        return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "    def _precision_at_k(self, true_items: List[int], pred_items: List[int], k: int) -> float:\n",
    "        \"\"\"\n",
    "        단일 사용자에 대한 Precision@K를 계산합니다.\n",
    "        추천 목록의 상위 K개 아이템 중 실제로 관련 있는 항목의 비율입니다.\n",
    "        \n",
    "        Args:\n",
    "            true_items: 실제 관련 있는 아이템 ID 리스트\n",
    "            pred_items: 예측/추천된 아이템 ID 리스트\n",
    "            k: 상위 K개 항목만 고려\n",
    "            \n",
    "        Returns:\n",
    "            Precision@K 값 (0~1 사이, 높을수록 좋음)\n",
    "        \"\"\"\n",
    "        if k == 0: return 0.0\n",
    "        return len(set(true_items) & set(pred_items[:k])) / k\n",
    "\n",
    "    def _recall_at_k(self, true_items: List[int], pred_items: List[int], k: int) -> float:\n",
    "        \"\"\"\n",
    "        단일 사용자에 대한 Recall@K를 계산합니다.\n",
    "        실제 관련 있는 항목 중 추천 목록의 상위 K개 항목에 포함된 비율입니다.\n",
    "        \n",
    "        Args:\n",
    "            true_items: 실제 관련 있는 아이템 ID 리스트\n",
    "            pred_items: 예측/추천된 아이템 ID 리스트\n",
    "            k: 상위 K개 항목만 고려\n",
    "            \n",
    "        Returns:\n",
    "            Recall@K 값 (0~1 사이, 높을수록 좋음)\n",
    "        \"\"\"\n",
    "        if len(true_items) == 0 or k == 0: return 0.0\n",
    "        return len(set(true_items) & set(pred_items[:k])) / len(true_items)\n",
    "\n",
    "    def _calc_precision_at_k(self, true_u2i, pred_u2i, k):\n",
    "        \"\"\"\n",
    "        모든 사용자에 대한 평균 Precision@K를 계산합니다.\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for u in true_u2i.keys():\n",
    "            scores.append(self._precision_at_k(true_u2i[u], pred_u2i.get(u, []), k))\n",
    "        return float(np.mean(scores)) if scores else 0.0\n",
    "\n",
    "    def _calc_recall_at_k(self, true_u2i, pred_u2i, k):\n",
    "        \"\"\"\n",
    "        모든 사용자에 대한 평균 Recall@K를 계산합니다.\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for u in true_u2i.keys():\n",
    "            scores.append(self._recall_at_k(true_u2i[u], pred_u2i.get(u, []), k))\n",
    "        return float(np.mean(scores)) if scores else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 메트릭스 사용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 간단한 예제로 메트릭스 계산기 시연\n",
    "# 실제 평점\n",
    "true_ratings = [5.0, 4.0, 3.0, 2.0, 1.0]\n",
    "# 예측 평점\n",
    "pred_ratings = [4.5, 3.5, 3.5, 1.5, 2.0]\n",
    "\n",
    "# 실제 사용자가 높이 평가한(관련 있는) 아이템 리스트\n",
    "true_u2i = {1: [101, 102, 103], 2: [201, 202]}\n",
    "# 추천된 아이템 목록\n",
    "pred_u2i = {1: [101, 104, 103, 105], 2: [203, 201, 204]}\n",
    "\n",
    "# 메트릭스 계산\n",
    "calculator = MetricCalculator()\n",
    "metrics = calculator.calc(true_ratings, pred_ratings, true_u2i, pred_u2i, k=3)\n",
    "\n",
    "print(f\"RMSE: {metrics.rmse:.3f}\")\n",
    "print(f\"Precision@3: {metrics.precision_at_k:.3f}\")\n",
    "print(f\"Recall@3: {metrics.recall_at_k:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 메트릭스 해석 방법\n",
    "\n",
    "추천 시스템의 성능은 다음 메트릭스로 평가합니다:\n",
    "\n",
    "1. **RMSE (Root Mean Squared Error)**:\n",
    "   - 예측 평점의 정확도를 측정\n",
    "   - 낮을수록 좋으며, 실제 평점과 예측 평점의 차이가 작음을 의미\n",
    "   - 주로 평점 예측 정확도 비교에 사용\n",
    "\n",
    "2. **Precision@K**:\n",
    "   - 추천된 상위 K개 아이템 중 실제로 사용자가 관심 있는 비율\n",
    "   - 높을수록 좋으며, 1.0이면 모든 추천이 관련성 있음\n",
    "   - 추천의 정확성을 측정\n",
    "\n",
    "3. **Recall@K**:\n",
    "   - 사용자가 관심 있는 모든 아이템 중 상위 K개 추천에 포함된 비율\n",
    "   - 높을수록 좋으며, 1.0이면 모든 관련 아이템이 추천됨\n",
    "   - 추천의 완전성을 측정\n",
    "\n",
    "이러한 메트릭스를 함께 고려하여 추천 시스템의 전체적인 성능을 평가합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}