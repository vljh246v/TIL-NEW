{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-24T09:17:52.327304Z",
     "start_time": "2025-09-24T09:17:52.200418Z"
    }
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# MovieLens ml-latest-small — 협업 필터링 과제용 통합 코드\n",
    "\n",
    "import os, io, zipfile, requests, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# =========================\n",
    "# A. 데이터 준비 / 전처리\n",
    "# =========================\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Dataset:\n",
    "    train: pd.DataFrame\n",
    "    test: pd.DataFrame\n",
    "    test_user2items: Dict[int, List[int]]\n",
    "    item_content: pd.DataFrame\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RecommendResult:\n",
    "    rating: pd.Series                  # test 인덱스와 정렬을 맞춘 예측값\n",
    "    user2items: Dict[int, List[int]]   # 추천 Top-K 목록\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Metrics:\n",
    "    rmse: float\n",
    "    precision_at_k: float\n",
    "    recall_at_k: float\n",
    "    params: Dict = dataclasses.field(default_factory=dict)\n",
    "    def __repr__(self):\n",
    "        return f\"rmse={self.rmse:.3f}, Precision@K={self.precision_at_k:.3f}, Recall@K={self.recall_at_k:.3f}, Params={self.params}\"\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, num_users: Optional[int] = 100, num_test_items: int = 5):\n",
    "        self.num_users = num_users\n",
    "        self.num_test_items = num_test_items\n",
    "        self.data_dir = \"./ml-latest-small\"\n",
    "        self.dataset_url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "\n",
    "    def _download_and_extract(self):\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            print(f\"Downloading dataset from {self.dataset_url}...\")\n",
    "            r = requests.get(self.dataset_url, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "            z.extractall(\".\")\n",
    "            print(\"Download and extraction complete!\")\n",
    "        else:\n",
    "            print(f\"Dataset already exists in {self.data_dir}\")\n",
    "\n",
    "    def load(self) -> Dataset:\n",
    "        self._download_and_extract()\n",
    "        ratings, movies = self._load_dataframes()\n",
    "        train, test = self._split_data(ratings)\n",
    "\n",
    "        test_user2items = (\n",
    "            test[test.rating >= 4].groupby(\"userId\")[\"movieId\"].apply(list).to_dict()\n",
    "        )\n",
    "        return Dataset(train, test, test_user2items, movies)\n",
    "\n",
    "    def _split_data(self, df: pd.DataFrame):\n",
    "        # 유저별 최근 5개를 Test\n",
    "        df = df.copy()\n",
    "        df[\"rating_order\"] = df.groupby(\"userId\")[\"timestamp\"].rank(ascending=False, method=\"first\")\n",
    "        train = df[df[\"rating_order\"] > self.num_test_items]\n",
    "        test  = df[df[\"rating_order\"] <= self.num_test_items]\n",
    "        return train, test\n",
    "\n",
    "    def _load_dataframes(self):\n",
    "        ratings = pd.read_csv(os.path.join(self.data_dir, \"ratings.csv\"))\n",
    "        movies  = pd.read_csv(os.path.join(self.data_dir, \"movies.csv\"))\n",
    "        if self.num_users is not None:\n",
    "            valid_users = sorted(ratings.userId.unique())[:self.num_users]\n",
    "            ratings = ratings[ratings.userId.isin(valid_users)]\n",
    "        return ratings, movies\n",
    "\n",
    "# =========================\n",
    "# 평가 유틸\n",
    "# =========================\n",
    "\n",
    "class MetricCalculator:\n",
    "    def calc(self, true_rating: List[float], pred_rating: List[float],\n",
    "             true_user2items: Dict[int, List[int]],\n",
    "             pred_user2items: Dict[int, List[int]], k: int, params: Dict=None) -> Metrics:\n",
    "        rmse = self._calc_rmse(true_rating, pred_rating)\n",
    "        p = self._calc_precision_at_k(true_user2items, pred_user2items, k)\n",
    "        r = self._calc_recall_at_k(true_user2items, pred_user2items, k)\n",
    "        return Metrics(rmse, p, r, params or {})\n",
    "\n",
    "    def _calc_rmse(self, y, yhat) -> float:\n",
    "        if not y or not yhat: return np.nan\n",
    "        return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "    def _precision_at_k(self, true_items: List[int], pred_items: List[int], k: int) -> float:\n",
    "        if k == 0: return 0.0\n",
    "        return len(set(true_items) & set(pred_items[:k])) / k\n",
    "\n",
    "    def _recall_at_k(self, true_items: List[int], pred_items: List[int], k: int) -> float:\n",
    "        if len(true_items) == 0 or k == 0: return 0.0\n",
    "        return len(set(true_items) & set(pred_items[:k])) / len(true_items)\n",
    "\n",
    "    def _calc_precision_at_k(self, true_u2i, pred_u2i, k):\n",
    "        scores = []\n",
    "        for u in true_u2i.keys():\n",
    "            scores.append(self._precision_at_k(true_u2i[u], pred_u2i.get(u, []), k))\n",
    "        return float(np.mean(scores)) if scores else 0.0\n",
    "\n",
    "    def _calc_recall_at_k(self, true_u2i, pred_u2i, k):\n",
    "        scores = []\n",
    "        for u in true_u2i.keys():\n",
    "            scores.append(self._recall_at_k(true_u2i[u], pred_u2i.get(u, []), k))\n",
    "        return float(np.mean(scores)) if scores else 0.0\n",
    "\n",
    "# =========================\n",
    "# B. 베이스라인\n",
    "# =========================\n",
    "\n",
    "class BaseRecommender:\n",
    "    def recommend(self, dataset: Dataset, **kwargs) -> RecommendResult:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalMeanRecommender(BaseRecommender):\n",
    "    \"\"\"전체 평균 기반 추천 시스템 (Baseline)\n",
    "\n",
    "    가장 단순한 형태의 추천 시스템으로, 모든 예측값을 전체 평점의 평균으로 설정합니다.\n",
    "    실제 추천 목록은 생성하지 않으며, 이는 다른 알고리즘의 성능을 비교하는 기준선으로 사용됩니다.\n",
    "\n",
    "    알고리즘 로직:\n",
    "    1. 훈련 데이터의 모든 평점 평균(μ)을 계산합니다\n",
    "    2. 모든 테스트 데이터의 예측값을 이 평균으로 설정합니다\n",
    "    3. 예측값을 0.5~5.0 범위로 제한합니다\n",
    "    4. 실제 추천 아이템 목록은 빈 리스트를 반환합니다\n",
    "    \"\"\"\n",
    "    def recommend(self, dataset: Dataset, **kwargs) -> RecommendResult:\n",
    "        mu = float(dataset.train['rating'].mean())\n",
    "        pred = pd.Series(mu, index=dataset.test.index).clip(lower=0.5, upper=5.0)\n",
    "        return RecommendResult(pred, defaultdict(list))\n",
    "\n",
    "class PopularityRecommender(BaseRecommender):\n",
    "    \"\"\"인기도 기반 추천 시스템\n",
    "\n",
    "    가장 많은 사용자가 평가한(인기 있는) 아이템을 추천하는 방식으로,\n",
    "    협업 필터링의 가장 단순한 형태입니다. 아이템 평가 횟수를 기준으로 인기도를 측정합니다.\n",
    "\n",
    "    알고리즘 로직:\n",
    "    1. RMSE 평가를 위한 평점 예측:\n",
    "       - 각 영화별 평균 평점을 계산합니다\n",
    "       - 테스트 데이터의 영화 ID에 맞는 평균 평점을 예측값으로 사용합니다\n",
    "       - 테스트 데이터에 없는 영화는 전체 평균(μ)으로 설정합니다\n",
    "       - 예측값을 0.5~5.0 범위로 제한합니다\n",
    "\n",
    "    2. 추천 목록 생성:\n",
    "       - 영화별로 평가 횟수(cnt)와 평균 평점(mean)을 계산합니다\n",
    "       - minimum_num_rating 이상 평가받은 영화만 고려합니다\n",
    "       - 평가 횟수 기준 내림차순, 동률 시 영화 ID 기준 오름차순으로 정렬합니다\n",
    "       - 각 사용자가 이미 평가한 영화를 제외한 상위 k개 영화를 추천합니다\n",
    "\n",
    "    매개변수:\n",
    "    - k: 추천 목록 크기 (기본값: 10)\n",
    "    - minimum_num_rating: 최소 평가 횟수 기준 (기본값: 0)\n",
    "    \"\"\"\n",
    "    def recommend(self, dataset: Dataset, k=10, minimum_num_rating=0, **kwargs) -> RecommendResult:\n",
    "        train, test = dataset.train, dataset.test\n",
    "        mu = float(train['rating'].mean())\n",
    "\n",
    "        # RMSE용: 영화별 평균 → 없는 영화 μ → clip\n",
    "        movie_mean = train.groupby('movieId')['rating'].mean().rename('rating_pred')\n",
    "        pred = test[['movieId']].merge(movie_mean, on='movieId', how='left')['rating_pred'].fillna(mu)\n",
    "        pred = pd.Series(pred.values, index=test.index).clip(lower=0.5, upper=5.0)\n",
    "\n",
    "        # 인기순: cnt desc, tie → movieId asc\n",
    "        stats = (train.groupby('movieId')['rating'].agg(cnt='count', mean='mean').reset_index())\n",
    "        stats = stats[stats['cnt'] >= minimum_num_rating]\n",
    "        stats = stats.sort_values(['cnt','movieId'], ascending=[False, True])\n",
    "        popular = stats['movieId'].tolist()\n",
    "\n",
    "        seen = train.groupby('userId')['movieId'].apply(set).to_dict()\n",
    "        user2items = defaultdict(list)\n",
    "        for u in test['userId'].unique():\n",
    "            s = seen.get(u, set())\n",
    "            rec = [m for m in popular if m not in s][:k]\n",
    "            user2items[u] = rec\n",
    "\n",
    "        return RecommendResult(pred, user2items)\n",
    "\n",
    "# =========================\n",
    "# C. 협업 필터링\n",
    "# =========================\n",
    "\n",
    "def _recommend_sorted(scores: Dict[int,float], seen: set, k: int) -> List[int]:\n",
    "    \"\"\"예측 점수를 기반으로 상위 k개 아이템을 추천 목록으로 생성하는 유틸리티 함수\n",
    "\n",
    "    1. 사용자가 아직 평가하지 않은 아이템 중에서 (seen에 없는 아이템)\n",
    "    2. 예측 점수가 높은 순서로 정렬하여 상위 k개 선택 (동일 점수는 아이템 ID 오름차순)\n",
    "\n",
    "    매개변수:\n",
    "    - scores: {아이템 ID: 예측 점수} 형태의 딕셔너리\n",
    "    - seen: 사용자가 이미 평가한 아이템 ID 집합\n",
    "    - k: 추천할 아이템 개수\n",
    "\n",
    "    반환값:\n",
    "    - 추천할 상위 k개 아이템 ID 리스트\n",
    "    \"\"\"\n",
    "    # (-score, movieId asc) 형태로 정렬\n",
    "    cands = ((m, s) for m, s in scores.items() if m not in seen)\n",
    "    return [m for m,_ in sorted(cands, key=lambda x: (-x[1], x[0]))[:k]]\n",
    "\n",
    "class UserKNNRecommender(BaseRecommender):\n",
    "    \"\"\"사용자 기반 협업 필터링 (User-based Collaborative Filtering)\n",
    "\n",
    "    유사한 사용자들이 좋아한 아이템을 추천하는 방식입니다.\n",
    "    사용자-아이템 평점 행렬에서 사용자 간 유사도를 계산하고,\n",
    "    타겟 사용자와 유사한 사용자들의 평점을 가중평균하여 예측합니다.\n",
    "\n",
    "    알고리즘 로직:\n",
    "    1. 사용자-아이템 행렬 생성:\n",
    "       - 행: 사용자 ID, 열: 영화 ID, 값: 평점\n",
    "       - 평가하지 않은 항목은 0으로 채움\n",
    "\n",
    "    2. 사용자 간 코사인 유사도 계산:\n",
    "       - 각 사용자 벡터 간의 코사인 유사도를 계산\n",
    "       - 유사도가 높을수록 취향이 비슷함을 의미\n",
    "\n",
    "    3. 평점 예측 (RMSE 계산용):\n",
    "       - 각 테스트 아이템에 대해 대상 사용자와 유사한 n_neighbors명의 이웃을 선택\n",
    "       - 이웃 중 해당 아이템을 평가한 사용자의 평점을 유사도로 가중평균하여 예측\n",
    "       - 이웃 중 아무도 해당 아이템을 평가하지 않았다면 전체 평균(μ) 사용\n",
    "       - 예측값을 0.5~5.0 범위로 제한\n",
    "\n",
    "    4. 아이템 추천:\n",
    "       - 각 사용자가 아직 평가하지 않은 모든 아이템에 대해 예측 평점을 계산\n",
    "       - 예측 평점이 높은 순으로 상위 k개 아이템을 추천\n",
    "\n",
    "    매개변수:\n",
    "    - k: 추천 목록 크기 (기본값: 10)\n",
    "    - n_neighbors: 유사도 계산에 사용할 이웃 수 (기본값: 20)\n",
    "    \"\"\"\n",
    "    def recommend(self, dataset: Dataset, k=10, n_neighbors=20, **kwargs) -> RecommendResult:\n",
    "        train, test = dataset.train, dataset.test\n",
    "        mu = float(train['rating'].mean())  # 전체 평점 평균\n",
    "\n",
    "        # 사용자-아이템 행렬 생성 (ui: User-Item matrix)\n",
    "        ui = train.pivot_table(index='userId', columns='movieId', values='rating').fillna(0.0)\n",
    "        # 사용자 간 코사인 유사도 계산\n",
    "        sim = cosine_similarity(ui)\n",
    "        sim_df = pd.DataFrame(sim, index=ui.index, columns=ui.index)\n",
    "        # 사용자별 이미 평가한 아이템 목록\n",
    "        seen = train.groupby('userId')['movieId'].apply(set).to_dict()\n",
    "\n",
    "        # RMSE 계산을 위한 평점 예측\n",
    "        pred = pd.Series(index=test.index, dtype=float)\n",
    "        for idx, row in test.iterrows():\n",
    "            u, i = row['userId'], row['movieId']  # 사용자 ID와 영화 ID\n",
    "            # 학습 데이터에 없는 사용자나 아이템은 전체 평균 사용\n",
    "            if (u not in ui.index) or (i not in ui.columns):\n",
    "                pred.at[idx] = mu; continue\n",
    "            # 자신을 제외한 가장 유사한 n_neighbors명의 이웃 선택\n",
    "            neigh = sim_df.loc[u].sort_values(ascending=False).iloc[1:n_neighbors+1]\n",
    "            # 선택된 이웃들의 해당 영화 평점\n",
    "            neigh_r = ui.loc[neigh.index, i]\n",
    "            # 해당 영화를 평가한 이웃만 선택 (평점 > 0)\n",
    "            mask = neigh_r > 0\n",
    "            if mask.sum()==0: pred.at[idx]=mu  # 평가한 이웃이 없으면 전체 평균 사용\n",
    "            else:\n",
    "                # 유사도를 가중치로 하여 평점 가중평균 계산\n",
    "                w = neigh[mask]; r = neigh_r[mask]; s=w.sum()\n",
    "                pred.at[idx] = float((w*r).sum()/s) if s>1e-8 else mu\n",
    "        # 예측값 범위 조정 (0.5~5.0)\n",
    "        pred = pred.clip(lower=0.5, upper=5.0)\n",
    "\n",
    "        # 추천 목록 생성\n",
    "        user2items = defaultdict(list)\n",
    "        for u in test['userId'].unique():\n",
    "            # 학습 데이터에 없는 사용자는 모든 영화에 평균 점수 부여\n",
    "            if u not in ui.index:\n",
    "                scores = {m: mu for m in ui.columns}\n",
    "            else:\n",
    "                # 아직 평가하지 않은 영화 목록\n",
    "                unseen = [m for m in ui.columns if m not in seen.get(u,set())]\n",
    "                # 가장 유사한 이웃 선택\n",
    "                neigh = sim_df.loc[u].sort_values(ascending=False).iloc[1:n_neighbors+1]\n",
    "                scores = {}\n",
    "                # 각 영화마다 예측 점수 계산\n",
    "                for i in unseen:\n",
    "                    neigh_r = ui.loc[neigh.index, i]\n",
    "                    mask = neigh_r > 0\n",
    "                    if mask.sum()==0: scores[i]=mu  # 평가한 이웃이 없으면 전체 평균 사용\n",
    "                    else:\n",
    "                        # 유사도 가중 평점 계산\n",
    "                        w=neigh[mask]; r=neigh_r[mask]; s=w.sum()\n",
    "                        scores[i]=float((w*r).sum()/s) if s>1e-8 else mu\n",
    "            # 점수가 높은 순서로 상위 k개 영화 추천\n",
    "            user2items[u] = _recommend_sorted(scores, seen.get(u,set()), k)\n",
    "        return RecommendResult(pred, user2items)\n",
    "\n",
    "class ItemKNNRecommender(BaseRecommender):\n",
    "    \"\"\"아이템 기반 협업 필터링 (Item-based Collaborative Filtering)\n",
    "\n",
    "    사용자가 평가한 아이템과 유사한 다른 아이템을 추천하는 방식입니다.\n",
    "    아이템 간 유사도를 계산하고, 사용자가 높이 평가한 아이템과 유사한 아이템을 추천합니다.\n",
    "\n",
    "    알고리즘 로직:\n",
    "    1. 사용자-아이템 행렬 생성 및 전치:\n",
    "       - 원본: 행=사용자, 열=영화\n",
    "       - 전치(iu): 행=영화, 열=사용자 (Item-User matrix)\n",
    "\n",
    "    2. 아이템 간 코사인 유사도 계산:\n",
    "       - 각 영화 벡터 간의 코사인 유사도를 계산\n",
    "       - 유사도가 높을수록 비슷한 영화임을 의미\n",
    "\n",
    "    3. 평점 예측 (RMSE 계산용):\n",
    "       - 예측할 영화와 가장 유사한 n_neighbors개의 영화를 선택\n",
    "       - 그 중 사용자가 평가한 영화들만 고려(common)\n",
    "       - 유사도를 가중치로 하여 사용자의 평점을 가중평균\n",
    "       - 유사한 영화를 사용자가 평가하지 않았다면 전체 평균(μ) 사용\n",
    "       - 예측값을 0.5~5.0 범위로 제한\n",
    "\n",
    "    4. 아이템 추천:\n",
    "       - 각 사용자가 아직 평가하지 않은 모든 영화에 대해 예측 평점 계산\n",
    "       - 예측 평점이 높은 순으로 상위 k개 영화를 추천\n",
    "\n",
    "    매개변수:\n",
    "    - k: 추천 목록 크기 (기본값: 10)\n",
    "    - n_neighbors: 유사도 계산에 사용할 이웃 수 (기본값: 20)\n",
    "\n",
    "    특징:\n",
    "    - 사용자 기반보다 일반적으로 더 안정적인 성능을 보임\n",
    "    - 아이템 간 유사도는 변화가 적어 미리 계산해두면 효율적\n",
    "    - Cold-start 문제에 비교적 강건함\n",
    "    \"\"\"\n",
    "    def recommend(self, dataset: Dataset, k=10, n_neighbors=20, **kwargs) -> RecommendResult:\n",
    "        train, test = dataset.train, dataset.test\n",
    "        mu = float(train['rating'].mean())  # 전체 평점 평균\n",
    "\n",
    "        # 사용자-아이템 행렬 생성 및 전치하여 아이템-사용자 행렬로 변환\n",
    "        ui = train.pivot_table(index='userId', columns='movieId', values='rating').fillna(0.0)\n",
    "        iu = ui.T  # 전치: 행=영화, 열=사용자\n",
    "        # 아이템 간 코사인 유사도 계산\n",
    "        sim = cosine_similarity(iu)\n",
    "        sim_df = pd.DataFrame(sim, index=iu.index, columns=iu.index)\n",
    "        # 사용자별 이미 평가한 아이템 목록\n",
    "        seen = train.groupby('userId')['movieId'].apply(set).to_dict()\n",
    "\n",
    "        # RMSE 계산을 위한 평점 예측\n",
    "        pred = pd.Series(index=test.index, dtype=float)\n",
    "        for idx, row in test.iterrows():\n",
    "            u, i = row['userId'], row['movieId']  # 사용자 ID와 영화 ID\n",
    "            # 학습 데이터에 없는 사용자나 아이템은 전체 평균 사용\n",
    "            if (u not in ui.index) or (i not in ui.columns):\n",
    "                pred.at[idx] = mu; continue\n",
    "            # 현재 영화와 가장 유사한 n_neighbors개의 영화 선택\n",
    "            sims = sim_df[i].sort_values(ascending=False).iloc[1:n_neighbors+1]\n",
    "            # 현재 사용자가 평가한 영화들\n",
    "            rated = ui.loc[u]\n",
    "            # 유사한 영화 중 사용자가 평가한 영화만 선택\n",
    "            common = sims.index[rated.loc[sims.index] > 0]\n",
    "            if len(common)==0: pred.at[idx]=mu  # 공통 영화가 없으면 전체 평균 사용\n",
    "            else:\n",
    "                # 유사도를 가중치로 하여 평점 가중평균 계산\n",
    "                w=sims.loc[common]; r=rated.loc[common]; s=w.sum()\n",
    "                pred.at[idx]=float((w*r).sum()/s) if s>1e-8 else mu\n",
    "        # 예측값 범위 조정 (0.5~5.0)\n",
    "        pred = pred.clip(lower=0.5, upper=5.0)\n",
    "\n",
    "        # 추천 목록 생성\n",
    "        user2items = defaultdict(list)\n",
    "        for u in test['userId'].unique():\n",
    "            # 학습 데이터에 없는 사용자는 모든 영화에 평균 점수 부여\n",
    "            if u not in ui.index:\n",
    "                scores = {m: mu for m in ui.columns}\n",
    "            else:\n",
    "                # 아직 평가하지 않은 영화 목록\n",
    "                unseen = [m for m in ui.columns if m not in seen.get(u,set())]\n",
    "                # 해당 사용자가 평가한 영화들\n",
    "                rated = ui.loc[u]\n",
    "                scores = {}\n",
    "                # 각 미평가 영화에 대해 예측 점수 계산\n",
    "                for i in unseen:\n",
    "                    # 현재 영화와 가장 유사한 n_neighbors개의 영화 선택\n",
    "                    sims = sim_df[i].sort_values(ascending=False).iloc[1:n_neighbors+1]\n",
    "                    # 유사한 영화 중 사용자가 평가한 영화만 선택\n",
    "                    common = sims.index[rated.loc[sims.index] > 0]\n",
    "                    if len(common)==0: scores[i]=mu  # 공통 영화가 없으면 전체 평균 사용\n",
    "                    else:\n",
    "                        # 유사도 가중 평점 계산\n",
    "                        w=sims.loc[common]; r=rated.loc[common]; s=w.sum()\n",
    "                        scores[i]=float((w*r).sum()/s) if s>1e-8 else mu\n",
    "            # 점수가 높은 순서로 상위 k개 영화 추천\n",
    "            user2items[u] = _recommend_sorted(scores, seen.get(u,set()), k)\n",
    "        return RecommendResult(pred, user2items)\n",
    "\n",
    "class MFRecommender(BaseRecommender):\n",
    "    \"\"\"행렬 분해(Matrix Factorization) 기반 추천 시스템\n",
    "\n",
    "    사용자-아이템 평점 행렬을 저차원의 잠재 요인(latent factor) 행렬로 분해하여\n",
    "    누락된 평점을 예측하는 방식입니다. 구현된 알고리즘은 SGD(Stochastic Gradient Descent)를\n",
    "    사용하여 최적화하는 기본적인 행렬 분해 모델입니다.\n",
    "\n",
    "    모델 수식:\n",
    "    예측 평점 r̂_ui = μ + bu + bi + p_u · q_i^T\n",
    "    여기서:\n",
    "    - μ: 전체 평균 평점\n",
    "    - bu: 사용자 u의 편향(bias)\n",
    "    - bi: 아이템 i의 편향(bias)\n",
    "    - p_u: 사용자 u의 잠재 요인 벡터\n",
    "    - q_i: 아이템 i의 잠재 요인 벡터\n",
    "\n",
    "    알고리즘 로직:\n",
    "    1. 전처리:\n",
    "       - 사용자 ID와 영화 ID를 내부 인덱스로 매핑\n",
    "       - 전체 평균(μ) 계산\n",
    "       - 사용자 요인 행렬(P), 아이템 요인 행렬(Q) 초기화\n",
    "       - 사용자 편향(bu), 아이템 편향(bi) 초기화\n",
    "\n",
    "    2. SGD 학습:\n",
    "       - 모든 학습 데이터에 대해 n_epochs 횟수만큼 반복\n",
    "       - 각 평점에 대해:\n",
    "         a. 현재 모델로 평점 예측\n",
    "         b. 오차(e) 계산\n",
    "         c. 경사하강법으로 파라미터 업데이트:\n",
    "            - 사용자 편향(bu) 업데이트\n",
    "            - 아이템 편향(bi) 업데이트\n",
    "            - 사용자 요인 벡터(P[u]) 업데이트\n",
    "            - 아이템 요인 벡터(Q[i]) 업데이트\n",
    "\n",
    "    3. 평점 예측 (RMSE 계산용):\n",
    "       - 테스트 데이터의 각 항목에 대해 학습된 모델로 평점 예측\n",
    "       - 예측값을 0.5~5.0 범위로 제한\n",
    "\n",
    "    4. 아이템 추천:\n",
    "       - 각 사용자에 대해 모든 아이템의 예측 평점 계산\n",
    "       - 이미 평가한 아이템을 제외하고 예측 평점이 높은 상위 k개 추천\n",
    "\n",
    "    매개변수:\n",
    "    - k: 추천 목록 크기 (기본값: 10)\n",
    "    - n_factors: 잠재 요인의 차원 수 (기본값: 20)\n",
    "    - learning_rate: 학습률 (기본값: 0.01)\n",
    "    - n_epochs: 반복 학습 횟수 (기본값: 50)\n",
    "    - reg: 정규화 계수 (기본값: 0.08)\n",
    "\n",
    "    특징:\n",
    "    - 메모리 기반 협업 필터링(UserKNN, ItemKNN)보다 일반적으로 더 높은 정확도\n",
    "    - 대용량 데이터에서도 효율적으로 학습 가능\n",
    "    - 사용자와 아이템의 잠재적 특성을 학습하여 데이터 희소성 문제를 완화\n",
    "    \"\"\"\n",
    "    def recommend(self, dataset: Dataset, k=10, **kwargs) -> RecommendResult:\n",
    "        np.random.seed(0)  # 재현성을 위한 시드 고정\n",
    "        # 하이퍼파라미터 설정\n",
    "        n_factors = kwargs.get('n_factors', 20)  # 잠재 요인 차원\n",
    "        lr = kwargs.get('learning_rate', 0.01)  # 학습률\n",
    "        n_epochs = kwargs.get('n_epochs', 50)   # 반복 학습 횟수\n",
    "        reg = kwargs.get('reg', 0.08)           # 정규화 계수\n",
    "\n",
    "        train, test = dataset.train, dataset.test\n",
    "        mu = float(train['rating'].mean())  # 전체 평균 평점\n",
    "\n",
    "        # ID를 내부 인덱스로 매핑\n",
    "        users = sorted(train.userId.unique())\n",
    "        items = sorted(train.movieId.unique())\n",
    "        uid2i = {u:i for i,u in enumerate(users)}  # 사용자 ID → 인덱스\n",
    "        iid2j = {m:j for j,m in enumerate(items)}  # 영화 ID → 인덱스\n",
    "        nU, nI = len(users), len(items)  # 사용자 수, 아이템 수\n",
    "\n",
    "        # 모델 파라미터 초기화\n",
    "        P = 0.1*np.random.randn(nU, n_factors)  # 사용자 요인 행렬\n",
    "        Q = 0.1*np.random.randn(nI, n_factors)  # 아이템 요인 행렬\n",
    "        bu = np.zeros(nU)  # 사용자 편향\n",
    "        bi = np.zeros(nI)  # 아이템 편향\n",
    "\n",
    "        # 학습 데이터 인덱스 매핑\n",
    "        df = train.copy()\n",
    "        df['ui'] = df['userId'].map(uid2i)  # 사용자 ID → 인덱스\n",
    "        df['ij'] = df['movieId'].map(iid2j)  # 영화 ID → 인덱스\n",
    "\n",
    "        # SGD로 모델 학습\n",
    "        for _ in range(n_epochs):\n",
    "            for r in df.itertuples(index=False):\n",
    "                u, j, y = int(r.ui), int(r.ij), float(r.rating)\n",
    "                # 예측값 계산: μ + bu + bi + p_u·q_i^T\n",
    "                pred = mu + bu[u] + bi[j] + P[u].dot(Q[j])\n",
    "                # 오차 계산\n",
    "                e = y - pred\n",
    "                # 파라미터 업데이트\n",
    "                bu[u] += lr*(e - reg*bu[u])  # 사용자 편향 업데이트\n",
    "                bi[j] += lr*(e - reg*bi[j])   # 아이템 편향 업데이트\n",
    "                Pu = P[u].copy(); Qj = Q[j].copy()  # 원본 보존\n",
    "                P[u] += lr*(e*Qj - reg*Pu)   # 사용자 요인 업데이트\n",
    "                Q[j] += lr*(e*Pu - reg*Qj)   # 아이템 요인 업데이트\n",
    "\n",
    "        # RMSE 계산을 위한 평점 예측\n",
    "        pred = pd.Series(index=test.index, dtype=float)\n",
    "        for idx, row in test.iterrows():\n",
    "            u, m = row['userId'], row['movieId']  # 사용자 ID와 영화 ID\n",
    "            # 학습 데이터에 없는 사용자나 아이템은 전체 평균 사용\n",
    "            if (u not in uid2i) or (m not in iid2j):\n",
    "                pred.at[idx] = mu\n",
    "            else:\n",
    "                # 인덱스 매핑\n",
    "                ui = uid2i[u]; ij = iid2j[m]\n",
    "                # 예측값 계산: μ + bu + bi + p_u·q_i^T\n",
    "                pred.at[idx] = mu + bu[ui] + bi[ij] + P[ui].dot(Q[ij])\n",
    "        # 예측값 범위 조정 (0.5~5.0)\n",
    "        pred = pred.clip(lower=0.5, upper=5.0)\n",
    "\n",
    "        # 추천 목록 생성\n",
    "        seen = train.groupby('userId')['movieId'].apply(set).to_dict()\n",
    "        user2items = defaultdict(list)\n",
    "        for u in test['userId'].unique():\n",
    "            # 학습 데이터에 없는 사용자는 모든 아이템에 평균 점수 부여\n",
    "            if u not in uid2i:\n",
    "                scores = {m: mu for m in items}\n",
    "            else:\n",
    "                # 모든 아이템에 대한 예측 점수를 한 번에 계산\n",
    "                ui = uid2i[u]\n",
    "                s = mu + bu[ui] + bi + Q @ P[ui]  # 행렬 곱을 통한 벡터화 연산\n",
    "                scores = {items[j]: float(s[j]) for j in range(nI)}\n",
    "            # 점수가 높은 순서로 상위 k개 아이템 추천\n",
    "            user2items[u] = _recommend_sorted(scores, seen.get(u,set()), k)\n",
    "\n",
    "        return RecommendResult(pred, user2items)\n",
    "\n",
    "# =========================\n",
    "# D. 실행 / 평가 / 출력\n",
    "# =========================\n",
    "\n",
    "def run_evaluation(model, dataset, k=10, **params) -> Metrics:\n",
    "    calc = MetricCalculator()\n",
    "    result = model().recommend(dataset, k=k, **params)\n",
    "    return calc.calc(\n",
    "        dataset.test['rating'].tolist(),\n",
    "        result.rating.tolist(),\n",
    "        dataset.test_user2items,\n",
    "        result.user2items,\n",
    "        k=k,\n",
    "        params={\"model\": model.__name__, **params}\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드 (전 유저 사용: num_users=None)\n",
    "    loader = DataLoader(num_users=None, num_test_items=5)\n",
    "    ds = loader.load()\n",
    "\n",
    "    K = 10\n",
    "    mc = MetricCalculator()\n",
    "\n",
    "    print(\"\\n=== Baselines ===\")\n",
    "    gm_res = GlobalMeanRecommender().recommend(ds)\n",
    "    gm_metrics = mc.calc(ds.test['rating'].tolist(), gm_res.rating.tolist(),\n",
    "                         ds.test_user2items, gm_res.user2items, k=K, params={\"model\":\"GlobalMean\"})\n",
    "    print(\"GlobalMean:\", gm_metrics)\n",
    "\n",
    "    pop_res = PopularityRecommender().recommend(ds, k=K, minimum_num_rating=0)\n",
    "    pop_metrics = mc.calc(ds.test['rating'].tolist(), pop_res.rating.tolist(),\n",
    "                          ds.test_user2items, pop_res.user2items, k=K, params={\"model\":\"Popularity\"})\n",
    "    print(\"Popularity:\", pop_metrics)\n",
    "\n",
    "    print(\"\\n=== CF (grid) ===\")\n",
    "    # UserKNN grid\n",
    "    uk_results = []\n",
    "    for n in [5, 10, 20]:\n",
    "        m = run_evaluation(UserKNNRecommender, ds, k=K, n_neighbors=n)\n",
    "        uk_results.append(m)\n",
    "        print(\"UserKNN:\", m)\n",
    "    best_uk = max(uk_results, key=lambda x: (x.precision_at_k, -x.rmse))\n",
    "\n",
    "    # ItemKNN grid\n",
    "    ik_results = []\n",
    "    for n in [5, 10, 20]:\n",
    "        m = run_evaluation(ItemKNNRecommender, ds, k=K, n_neighbors=n)\n",
    "        ik_results.append(m)\n",
    "        print(\"ItemKNN:\", m)\n",
    "    best_ik = max(ik_results, key=lambda x: (x.precision_at_k, -x.rmse))\n",
    "\n",
    "    # MF grid\n",
    "    mf_results = []\n",
    "    for f in [10, 20, 50]:\n",
    "        m = run_evaluation(MFRecommender, ds, k=K, n_factors=f, learning_rate=0.02, n_epochs=30, reg=0.08)\n",
    "        mf_results.append(m)\n",
    "        print(\"MF:\", m)\n",
    "    best_mf = max(mf_results, key=lambda x: (x.precision_at_k, -x.rmse))\n",
    "\n",
    "    # 결과 표\n",
    "    df = pd.DataFrame([\n",
    "        {\"Model\":\"Global Mean\", \"RMSE\": gm_metrics.rmse, \"Precision@10\": np.nan, \"Recall@10\": np.nan},\n",
    "        {\"Model\":\"Popularity\",  \"RMSE\": pop_metrics.rmse, \"Precision@10\": pop_metrics.precision_at_k, \"Recall@10\": pop_metrics.recall_at_k},\n",
    "        {\"Model\":\"UserKNN\",     \"RMSE\": best_uk.rmse,     \"Precision@10\": best_uk.precision_at_k,     \"Recall@10\": best_uk.recall_at_k},\n",
    "        {\"Model\":\"ItemKNN\",     \"RMSE\": best_ik.rmse,     \"Precision@10\": best_ik.precision_at_k,     \"Recall@10\": best_ik.recall_at_k},\n",
    "        {\"Model\":\"MF\",          \"RMSE\": best_mf.rmse,     \"Precision@10\": best_mf.precision_at_k,     \"Recall@10\": best_mf.recall_at_k},\n",
    "    ])\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(df.to_markdown(index=False))\n",
    "\n",
    "    # 성공 기준 체크(참고 출력)\n",
    "    def pct_improve(a, b):  # a→b로 개선율(+, 나쁨은 음수)\n",
    "        return None if (a is None or np.isnan(a) or b is None or np.isnan(b)) else 100.0*(a-b)/a\n",
    "    rmse_gain_user = pct_improve(gm_metrics.rmse, best_uk.rmse)\n",
    "    rmse_gain_item = pct_improve(gm_metrics.rmse, best_ik.rmse)\n",
    "    rmse_gain_mf   = pct_improve(gm_metrics.rmse, best_mf.rmse)\n",
    "\n",
    "    print(\"\\n=== Goal Check ===\")\n",
    "    print(f\"RMSE vs GlobalMean — UserKNN: {rmse_gain_user:.2f}% / ItemKNN: {rmse_gain_item:.2f}% / MF: {rmse_gain_mf:.2f}%\")\n",
    "    print(f\"Precision@{K} vs Popularity — UserKNN: {best_uk.precision_at_k - pop_metrics.precision_at_k:+.3f}, \"\n",
    "          f\"ItemKNN: {best_ik.precision_at_k - pop_metrics.precision_at_k:+.3f}, \"\n",
    "          f\"MF: {best_mf.precision_at_k - pop_metrics.precision_at_k:+.3f}\")\n",
    "    print(f\"Recall@{K} vs Popularity — UserKNN: {best_uk.recall_at_k - pop_metrics.recall_at_k:+.3f}, \"\n",
    "          f\"ItemKNN: {best_ik.recall_at_k - pop_metrics.recall_at_k:+.3f}, \"\n",
    "          f\"MF: {best_mf.recall_at_k - pop_metrics.recall_at_k:+.3f}\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# =========================\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# D. 실행 / 평가 / 출력\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# =========================\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrun_evaluation\u001B[39m(model, dataset, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[43mMetrics\u001B[49m:\n\u001B[1;32m      6\u001B[0m     calc \u001B[38;5;241m=\u001B[39m MetricCalculator()\n\u001B[1;32m      7\u001B[0m     result \u001B[38;5;241m=\u001B[39m model()\u001B[38;5;241m.\u001B[39mrecommend(dataset, k\u001B[38;5;241m=\u001B[39mk, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Metrics' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
